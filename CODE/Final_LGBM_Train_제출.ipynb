{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "import optuna\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Using categorical_feature in Dataset.\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Cannot compute class probabilities\")\n",
    "import os, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import cloudpickle\n",
    "\n",
    "LGBM_PARAMS_FOLD1 = {\n",
    "    1: {   \n",
    "        \"n_estimators\": 787, \"max_depth\": 5, \"learning_rate\": 0.11888702656176657,\n",
    "        \"num_leaves\": 49, \"subsample\": 0.624484926247728, \"colsample_bytree\": 0.8786168561044891,\n",
    "        \"min_child_samples\": 178, \"min_data_in_bin\": 131, \"max_bin\": 19,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    2: {   \n",
    "        \"n_estimators\": 2545, \"max_depth\": 7, \"learning_rate\": 0.007634724371543521,\n",
    "        \"num_leaves\": 51, \"subsample\": 0.7592383639346855, \"colsample_bytree\": 0.6638250722917066,\n",
    "        \"min_child_samples\": 227, \"min_data_in_bin\": 112, \"max_bin\": 107,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    3: {   \n",
    "        \"n_estimators\": 831, \"max_depth\": 5, \"learning_rate\": 0.037418597956376434,\n",
    "        \"num_leaves\": 121, \"subsample\": 0.7583721183200511, \"colsample_bytree\": 0.9713762639057146,\n",
    "        \"min_child_samples\": 215, \"min_data_in_bin\": 84, \"max_bin\": 112,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    4: {           \"n_estimators\": 1404, \"max_depth\": 5, \"learning_rate\": 0.02476554297139633,\n",
    "        \"num_leaves\": 248, \"subsample\": 0.858649289098756, \"colsample_bytree\": 0.9488606110791292,\n",
    "        \"min_child_samples\": 243, \"min_data_in_bin\": 71, \"max_bin\": 39,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    5: {   \n",
    "        \"n_estimators\": 2634, \"max_depth\": 6, \"learning_rate\": 0.007292070285611959,\n",
    "        \"num_leaves\": 170, \"subsample\": 0.7330642070719995, \"colsample_bytree\": 0.9365011737985862,\n",
    "        \"min_child_samples\": 294, \"min_data_in_bin\": 76, \"max_bin\": 122,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    6: {   \n",
    "        \"n_estimators\": 1425, \"max_depth\": 6, \"learning_rate\": 0.014866031621338526,\n",
    "        \"num_leaves\": 245, \"subsample\": 0.9635006059735503, \"colsample_bytree\": 0.7388340755797164,\n",
    "        \"min_child_samples\": 265, \"min_data_in_bin\": 131, \"max_bin\": 59,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    7: {   \n",
    "        \"n_estimators\": 1742, \"max_depth\": 4, \"learning_rate\": 0.06144272950148138,\n",
    "        \"num_leaves\": 228, \"subsample\": 0.7773970853357063, \"colsample_bytree\": 0.9535978677743406,\n",
    "        \"min_child_samples\": 290, \"min_data_in_bin\": 63, \"max_bin\": 57,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    8: {   \n",
    "        \"n_estimators\": 914, \"max_depth\": 7, \"learning_rate\": 0.010572012521806689,\n",
    "        \"num_leaves\": 110, \"subsample\": 0.9660826725596817, \"colsample_bytree\": 0.7431948336351859,\n",
    "        \"min_child_samples\": 285, \"min_data_in_bin\": 114, \"max_bin\": 79,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    9: {   \n",
    "        \"n_estimators\": 2050, \"max_depth\": 5, \"learning_rate\": 0.061308461800532496,\n",
    "        \"num_leaves\": 54, \"subsample\": 0.9471461609049571, \"colsample_bytree\": 0.8892411363119499,\n",
    "        \"min_child_samples\": 213, \"min_data_in_bin\": 103, \"max_bin\": 36,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    10: {   \n",
    "        \"n_estimators\": 1485, \"max_depth\": 3, \"learning_rate\": 0.10149842660519477,\n",
    "        \"num_leaves\": 68, \"subsample\": 0.8387005579330761, \"colsample_bytree\": 0.6355713314569621,\n",
    "        \"min_child_samples\": 211, \"min_data_in_bin\": 114, \"max_bin\": 52,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    11: {   \n",
    "        \"n_estimators\": 1730, \"max_depth\": 4, \"learning_rate\": 0.04381151036138411,\n",
    "        \"num_leaves\": 192, \"subsample\": 0.971752416486378, \"colsample_bytree\": 0.8726056080173101,\n",
    "        \"min_child_samples\": 290, \"min_data_in_bin\": 126, \"max_bin\": 56,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    12: {   \n",
    "        \"n_estimators\": 1230, \"max_depth\": 7, \"learning_rate\": 0.023399787532239053,\n",
    "        \"num_leaves\": 248, \"subsample\": 0.8802726649690062, \"colsample_bytree\": 0.6148268641802005,\n",
    "        \"min_child_samples\": 212, \"min_data_in_bin\": 106, \"max_bin\": 112,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    13: {   \n",
    "        \"n_estimators\": 1862, \"max_depth\": 6, \"learning_rate\": 0.009742180507464527,\n",
    "        \"num_leaves\": 100, \"subsample\": 0.6426266202473732, \"colsample_bytree\": 0.7698091569193439,\n",
    "        \"min_child_samples\": 296, \"min_data_in_bin\": 76, \"max_bin\": 64,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    14: {   \n",
    "        \"n_estimators\": 1522, \"max_depth\": 5, \"learning_rate\": 0.012481395790033477,\n",
    "        \"num_leaves\": 55, \"subsample\": 0.6970425718655805, \"colsample_bytree\": 0.7901969475709782,\n",
    "        \"min_child_samples\": 181, \"min_data_in_bin\": 83, \"max_bin\": 22,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    15: {   \n",
    "        \"n_estimators\": 2018, \"max_depth\": 5, \"learning_rate\": 0.03357964988180808,\n",
    "        \"num_leaves\": 29, \"subsample\": 0.7221141242810662, \"colsample_bytree\": 0.8685632140319628,\n",
    "        \"min_child_samples\": 190, \"min_data_in_bin\": 89, \"max_bin\": 96,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    16: {   \n",
    "        \"n_estimators\": 954, \"max_depth\": 7, \"learning_rate\": 0.04536654054712942,\n",
    "        \"num_leaves\": 83, \"subsample\": 0.961406297703172, \"colsample_bytree\": 0.7580691034602708,\n",
    "        \"min_child_samples\": 297, \"min_data_in_bin\": 149, \"max_bin\": 68,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    17: {   \n",
    "        \"n_estimators\": 2401, \"max_depth\": 6, \"learning_rate\": 0.04281199756433152,\n",
    "        \"num_leaves\": 72, \"subsample\": 0.6643343756921245, \"colsample_bytree\": 0.8725031998323545,\n",
    "        \"min_child_samples\": 283, \"min_data_in_bin\": 66, \"max_bin\": 122,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    18: {   \n",
    "        \"n_estimators\": 2786, \"max_depth\": 5, \"learning_rate\": 0.01614129625436229,\n",
    "        \"num_leaves\": 144, \"subsample\": 0.7331703303024892, \"colsample_bytree\": 0.7750686110943447,\n",
    "        \"min_child_samples\": 233, \"min_data_in_bin\": 141, \"max_bin\": 115,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    19: {   \n",
    "        \"n_estimators\": 424, \"max_depth\": 7, \"learning_rate\": 0.06434812016280046,\n",
    "        \"num_leaves\": 67, \"subsample\": 0.8575222323410057, \"colsample_bytree\": 0.9170968753383291,\n",
    "        \"min_child_samples\": 178, \"min_data_in_bin\": 143, \"max_bin\": 79,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    20: {   \n",
    "        \"n_estimators\": 792, \"max_depth\": 6, \"learning_rate\": 0.013668496566593805,\n",
    "        \"num_leaves\": 248, \"subsample\": 0.7148904277117937, \"colsample_bytree\": 0.9405304884200276,\n",
    "        \"min_child_samples\": 163, \"min_data_in_bin\": 55, \"max_bin\": 29,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    21: {   \n",
    "        \"n_estimators\": 2591, \"max_depth\": 6, \"learning_rate\": 0.022802583600631532,\n",
    "        \"num_leaves\": 55, \"subsample\": 0.8016747395637491, \"colsample_bytree\": 0.8775004606782648,\n",
    "        \"min_child_samples\": 176, \"min_data_in_bin\": 114, \"max_bin\": 67,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    22: {           \"n_estimators\": 2931, \"max_depth\": 7, \"learning_rate\": 0.01215565952554003,\n",
    "        \"num_leaves\": 35, \"subsample\": 0.8444934004017612, \"colsample_bytree\": 0.6941563396591417,\n",
    "        \"min_child_samples\": 222, \"min_data_in_bin\": 97, \"max_bin\": 61,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    23: {   \n",
    "        \"n_estimators\": 1928, \"max_depth\": 4, \"learning_rate\": 0.03622110949246611,\n",
    "        \"num_leaves\": 215, \"subsample\": 0.6745923904901094, \"colsample_bytree\": 0.773107109720554,\n",
    "        \"min_child_samples\": 273, \"min_data_in_bin\": 67, \"max_bin\": 111,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    24: {   \n",
    "        \"n_estimators\": 1702, \"max_depth\": 5, \"learning_rate\": 0.018639025657691953,\n",
    "        \"num_leaves\": 248, \"subsample\": 0.975054098097098, \"colsample_bytree\": 0.802046061222379,\n",
    "        \"min_child_samples\": 191, \"min_data_in_bin\": 110, \"max_bin\": 47,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    25: {   \n",
    "        \"n_estimators\": 1560, \"max_depth\": 7, \"learning_rate\": 0.02067739418139488,\n",
    "        \"num_leaves\": 184, \"subsample\": 0.6407716893263038, \"colsample_bytree\": 0.6943916207792031,\n",
    "        \"min_child_samples\": 189, \"min_data_in_bin\": 148, \"max_bin\": 39,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    26: {   \n",
    "        \"n_estimators\": 1853, \"max_depth\": 5, \"learning_rate\": 0.014586270332801177,\n",
    "        \"num_leaves\": 239, \"subsample\": 0.8536990959494131, \"colsample_bytree\": 0.8780707415194401,\n",
    "        \"min_child_samples\": 200, \"min_data_in_bin\": 58, \"max_bin\": 122,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    27: {   \n",
    "        \"n_estimators\": 2063, \"max_depth\": 5, \"learning_rate\": 0.030875318598399763,\n",
    "        \"num_leaves\": 114, \"subsample\": 0.6141242545387388, \"colsample_bytree\": 0.9414057704078651,\n",
    "        \"min_child_samples\": 150, \"min_data_in_bin\": 114, \"max_bin\": 88,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    28: {   \n",
    "        \"n_estimators\": 1647, \"max_depth\": 4, \"learning_rate\": 0.11103791026899788,\n",
    "        \"num_leaves\": 174, \"subsample\": 0.6690997283137835, \"colsample_bytree\": 0.6821711141794571,\n",
    "        \"min_child_samples\": 185, \"min_data_in_bin\": 77, \"max_bin\": 57,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    29: {   \n",
    "        \"n_estimators\": 1399, \"max_depth\": 6, \"learning_rate\": 0.05340806440872384,\n",
    "        \"num_leaves\": 153, \"subsample\": 0.7427141977250447, \"colsample_bytree\": 0.7760379878879242,\n",
    "        \"min_child_samples\": 190, \"min_data_in_bin\": 83, \"max_bin\": 99,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    30: {   \n",
    "        \"n_estimators\": 2277, \"max_depth\": 4, \"learning_rate\": 0.0787545923494326,\n",
    "        \"num_leaves\": 138, \"subsample\": 0.85669381198668, \"colsample_bytree\": 0.6614817810278202,\n",
    "        \"min_child_samples\": 256, \"min_data_in_bin\": 55, \"max_bin\": 113,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    31: {   \n",
    "        \"n_estimators\": 1517, \"max_depth\": 4, \"learning_rate\": 0.09689830654046962,\n",
    "        \"num_leaves\": 181, \"subsample\": 0.7038958707706676, \"colsample_bytree\": 0.6547815086573285,\n",
    "        \"min_child_samples\": 276, \"min_data_in_bin\": 52, \"max_bin\": 73,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    32: {   \n",
    "        \"n_estimators\": 2432, \"max_depth\": 5, \"learning_rate\": 0.02064814511449612,\n",
    "        \"num_leaves\": 131, \"subsample\": 0.7368591966435177, \"colsample_bytree\": 0.7755960965223485,\n",
    "        \"min_child_samples\": 245, \"min_data_in_bin\": 87, \"max_bin\": 49,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    33: {   \n",
    "        \"n_estimators\": 1348, \"max_depth\": 7, \"learning_rate\": 0.014355521620662942,\n",
    "        \"num_leaves\": 49, \"subsample\": 0.6895380093370882, \"colsample_bytree\": 0.7916574431110359,\n",
    "        \"min_child_samples\": 248, \"min_data_in_bin\": 85, \"max_bin\": 56,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    34: {   \n",
    "        \"n_estimators\": 1442, \"max_depth\": 7, \"learning_rate\": 0.020429963723104565,\n",
    "        \"num_leaves\": 171, \"subsample\": 0.8402872247888175, \"colsample_bytree\": 0.7938409837598009,\n",
    "        \"min_child_samples\": 272, \"min_data_in_bin\": 76, \"max_bin\": 33,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    35: {   \n",
    "        \"n_estimators\": 905, \"max_depth\": 7, \"learning_rate\": 0.04516161204021963,\n",
    "        \"num_leaves\": 148, \"subsample\": 0.6175472140033982, \"colsample_bytree\": 0.6831267091488763,\n",
    "        \"min_child_samples\": 237, \"min_data_in_bin\": 86, \"max_bin\": 95,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    36: {   \n",
    "        \"n_estimators\": 2472, \"max_depth\": 6, \"learning_rate\": 0.008731864938850442,\n",
    "        \"num_leaves\": 218, \"subsample\": 0.6593979188682272, \"colsample_bytree\": 0.931259450329502,\n",
    "        \"min_child_samples\": 234, \"min_data_in_bin\": 74, \"max_bin\": 117,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    37: {   \n",
    "        \"n_estimators\": 1312, \"max_depth\": 5, \"learning_rate\": 0.019500013036682938,\n",
    "        \"num_leaves\": 217, \"subsample\": 0.8043306819853238, \"colsample_bytree\": 0.6694824303828676,\n",
    "        \"min_child_samples\": 244, \"min_data_in_bin\": 130, \"max_bin\": 40,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    38: {   \n",
    "        \"n_estimators\": 701, \"max_depth\": 7, \"learning_rate\": 0.04928199210911576,\n",
    "        \"num_leaves\": 86, \"subsample\": 0.7553454828084172, \"colsample_bytree\": 0.844035512619168,\n",
    "        \"min_child_samples\": 261, \"min_data_in_bin\": 64, \"max_bin\": 46,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    39: {   \n",
    "        \"n_estimators\": 1927, \"max_depth\": 7, \"learning_rate\": 0.010535260733659919,\n",
    "        \"num_leaves\": 77, \"subsample\": 0.9783187471094477, \"colsample_bytree\": 0.8502685265345453,\n",
    "        \"min_child_samples\": 206, \"min_data_in_bin\": 145, \"max_bin\": 80,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    40: {   \n",
    "        \"n_estimators\": 2854, \"max_depth\": 7, \"learning_rate\": 0.004478288732823794,\n",
    "        \"num_leaves\": 178, \"subsample\": 0.7592788725858607, \"colsample_bytree\": 0.842822877226102,\n",
    "        \"min_child_samples\": 252, \"min_data_in_bin\": 81, \"max_bin\": 41,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    41: {   \n",
    "        \"n_estimators\": 634, \"max_depth\": 6, \"learning_rate\": 0.040002805110895684,\n",
    "        \"num_leaves\": 27, \"subsample\": 0.8375244876050991, \"colsample_bytree\": 0.7279309453233449,\n",
    "        \"min_child_samples\": 174, \"min_data_in_bin\": 111, \"max_bin\": 103,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    42: {   \n",
    "        \"n_estimators\": 1451, \"max_depth\": 5, \"learning_rate\": 0.040625112645048395,\n",
    "        \"num_leaves\": 240, \"subsample\": 0.9894242182583596, \"colsample_bytree\": 0.9319527831669929,\n",
    "        \"min_child_samples\": 250, \"min_data_in_bin\": 67, \"max_bin\": 110,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    43: {   \n",
    "        \"n_estimators\": 1683, \"max_depth\": 6, \"learning_rate\": 0.011725546813576068,\n",
    "        \"num_leaves\": 160, \"subsample\": 0.6639008054682066, \"colsample_bytree\": 0.7527959782219575,\n",
    "        \"min_child_samples\": 292, \"min_data_in_bin\": 112, \"max_bin\": 118,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    44: {   \n",
    "        \"n_estimators\": 2912, \"max_depth\": 5, \"learning_rate\": 0.01490884443752875,\n",
    "        \"num_leaves\": 183, \"subsample\": 0.7002062710120835, \"colsample_bytree\": 0.8213846498346755,\n",
    "        \"min_child_samples\": 175, \"min_data_in_bin\": 95, \"max_bin\": 84,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    45: {   \n",
    "        \"n_estimators\": 1846, \"max_depth\": 7, \"learning_rate\": 0.007481338855494027,\n",
    "        \"num_leaves\": 55, \"subsample\": 0.9190595975597214, \"colsample_bytree\": 0.814763134466031,\n",
    "        \"min_child_samples\": 236, \"min_data_in_bin\": 115, \"max_bin\": 101,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    46: {   \n",
    "        \"n_estimators\": 2341, \"max_depth\": 6, \"learning_rate\": 0.01683575376697604,\n",
    "        \"num_leaves\": 207, \"subsample\": 0.8915855466215947, \"colsample_bytree\": 0.8971223690234296,\n",
    "        \"min_child_samples\": 207, \"min_data_in_bin\": 143, \"max_bin\": 33,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    47: {   \n",
    "        \"n_estimators\": 1079, \"max_depth\": 7, \"learning_rate\": 0.04278605172397528,\n",
    "        \"num_leaves\": 195, \"subsample\": 0.9988003528843125, \"colsample_bytree\": 0.9218919458619116,\n",
    "        \"min_child_samples\": 227, \"min_data_in_bin\": 90, \"max_bin\": 118,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    48: {   \n",
    "        \"n_estimators\": 2942, \"max_depth\": 6, \"learning_rate\": 0.007361272909271433,\n",
    "        \"num_leaves\": 39, \"subsample\": 0.6650818177651044, \"colsample_bytree\": 0.7430242823690123,\n",
    "        \"min_child_samples\": 269, \"min_data_in_bin\": 114, \"max_bin\": 39,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    49: {   \n",
    "        \"n_estimators\": 2526, \"max_depth\": 5, \"learning_rate\": 0.021926141636690447,\n",
    "        \"num_leaves\": 154, \"subsample\": 0.7381487372175274, \"colsample_bytree\": 0.8181108224139191,\n",
    "        \"min_child_samples\": 186, \"min_data_in_bin\": 110, \"max_bin\": 79,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    50: {   \n",
    "        \"n_estimators\": 2316, \"max_depth\": 7, \"learning_rate\": 0.009010720601065036,\n",
    "        \"num_leaves\": 85, \"subsample\": 0.8027946022889386, \"colsample_bytree\": 0.9097175643982146,\n",
    "        \"min_child_samples\": 201, \"min_data_in_bin\": 59, \"max_bin\": 91,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "    51: {   \n",
    "        \"n_estimators\": 956, \"max_depth\": 6, \"learning_rate\": 0.028277860934774943,\n",
    "        \"num_leaves\": 38, \"subsample\": 0.9424854854284263, \"colsample_bytree\": 0.8438071695862728,\n",
    "        \"min_child_samples\": 189, \"min_data_in_bin\": 73, \"max_bin\": 43,\n",
    "        \"random_state\": 724, \"device\": \"cpu\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"train_preprocess_Final.parquet\")\n",
    "test = pd.read_parquet(\"test_preprocess_Final.parquet\")\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "cat_list = train.select_dtypes(include=['category','object']).columns.tolist()\n",
    "\n",
    "X_test = test.copy()\n",
    "test_preds = []  \n",
    "\n",
    "pos_df = train[train['clicked'] == 1].reset_index(drop=True)\n",
    "neg_df = train[train['clicked'] == 0].reset_index(drop=True)\n",
    "\n",
    "n_pos = len(pos_df)\n",
    "n_neg = len(neg_df)\n",
    "\n",
    "n_iters = int(np.ceil(n_neg / n_pos))\n",
    "\n",
    "print(f\"ğŸ” ë°˜ë³µ íšŸìˆ˜: {n_iters} (1:1 ë¹„ìœ¨ ìœ ì§€, ì „ì²´ 0 ìƒ˜í”Œ ì†Œì§„)\")\n",
    "\n",
    "# --------------------------\n",
    "# AP + WLL ì¡°í•© ìŠ¤ì½”ì–´\n",
    "# --------------------------\n",
    "def _ap_wll_score(y_true, y_prob):\n",
    "    eps = 1e-15\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    p = np.clip(np.asarray(y_prob, dtype=float), eps, 1 - eps)\n",
    "    n_pos = (y_true == 1).sum()\n",
    "    n_neg = (y_true == 0).sum()\n",
    "\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        ap = 0.0\n",
    "    else:\n",
    "        ap = average_precision_score(y_true, p)\n",
    "        if np.isnan(ap):\n",
    "            ap = 0.0\n",
    "\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        weights = np.ones_like(y_true, dtype=float) / len(y_true)\n",
    "    else:\n",
    "        w_pos = 0.5 / n_pos\n",
    "        w_neg = 0.5 / n_neg\n",
    "        weights = np.where(y_true == 1, w_pos, w_neg)\n",
    "\n",
    "    wll = -np.sum(weights * (y_true * np.log(p) + (1 - y_true) * np.log(1 - p)))\n",
    "    return 0.5 * ap + 0.5 * (1.0 / (1.0 + wll))\n",
    "\n",
    "def ap_wll_scorer(y_true, y_pred):\n",
    "    return _ap_wll_score(y_true, y_pred)\n",
    "\n",
    "# ===========================\n",
    "# ğŸ”§ Robust Aggregation \n",
    "# ===========================\n",
    "USE_RELATIVE_DOWNSIDE_STD = True  \n",
    "ROBUST_LAMBDA_RELATIVE_DSTD = 1 \n",
    "\n",
    "def aggregate_scores_relative_downside_std(scores, lam=0.4):\n",
    "    \"\"\"\n",
    "    ìƒëŒ€ì ì¸ Downside í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ëŠ” robust score.\n",
    "    downside_std / mean í˜•íƒœë¡œ ì •ê·œí™”ëœ penalized mean.\n",
    "    \"\"\"\n",
    "    s = np.asarray(scores, float)\n",
    "    if len(s) == 0:\n",
    "        return 0.0\n",
    "    mean_score = s.mean()\n",
    "    downside = np.minimum(0.0, s - mean_score)\n",
    "    downside_std = np.sqrt(np.mean(downside**2))\n",
    "    relative_dstd = downside_std / mean_score\n",
    "    return mean_score - lam * relative_dstd\n",
    "\n",
    "# =======================================================\n",
    "# ğŸ”¹ l_feat_14 value_counts ê¸°ë°˜ \"ì»¤ìŠ¤í…€ ì†ì‹¤\" ìœ í‹¸\n",
    "# =======================================================\n",
    "LF14_COL = \"l_feat_14\"   # ê°€ì¤‘ ê¸°ì¤€ ì»¬ëŸ¼\n",
    "WEIGHT_ALPHA = 0.5       \n",
    "W_MIN, W_MAX = 0.25, 4.0 \n",
    "\n",
    "def make_lf14_weights(X, col=LF14_COL,\n",
    "                      alpha=WEIGHT_ALPHA, wmin=W_MIN, wmax=W_MAX):\n",
    "    s = X[col].astype(\"category\")\n",
    "    vc = s.value_counts()\n",
    "    raw_w = s.map(vc).astype(float)\n",
    "    raw_w = (1.0 / np.maximum(raw_w, 1.0) ** alpha).values\n",
    "    raw_w = np.clip(raw_w, wmin, wmax)\n",
    "    raw_w = raw_w * (len(raw_w) / np.sum(raw_w))  # mean ~= 1\n",
    "    return raw_w.astype(np.float64)\n",
    "\n",
    "def make_weighted_logloss_objective(sample_weights):\n",
    "    sample_weights = np.asarray(sample_weights, dtype=np.float64)\n",
    "    def _obj(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true, dtype=np.float64)\n",
    "        # sigmoid(raw)\n",
    "        p = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "        grad = (p - y_true) * sample_weights\n",
    "        hess = (p * (1.0 - p)) * sample_weights\n",
    "        return grad, hess\n",
    "    return _obj\n",
    "\n",
    "def lgbm_proba1_from_raw(model, X):\n",
    "    raw = model.predict(X, raw_score=True)              \n",
    "    return 1.0 / (1.0 + np.exp(-raw))   \n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# ê²€ì¦ì…‹ì„ ì—¬ëŸ¬ê°œë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜ (ì‹¤ì œ ë¶„í¬ ë°˜ì˜ + ì„ íƒì  ë§ˆìŠ¤í‚¹)\n",
    "# --------------------------\n",
    "def make_real_ratio_valid_sets(\n",
    "    X_val, y_val,\n",
    "    target_ratio=0.019075,\n",
    "    mask_lf14_frac=0.15,          \n",
    "    mask_inventory_frac=0.05,      \n",
    "    mask_token=-111111,\n",
    "    inv_col=\"inventory_id\",\n",
    "    seed_pair=(724, 724)          \n",
    "):\n",
    "    X_val0 = X_val[y_val == 0].reset_index(drop=True)\n",
    "    X_val1 = X_val[y_val == 1].reset_index(drop=True)\n",
    "    n0, n1 = len(X_val0), len(X_val1)\n",
    "\n",
    "    valid_sets = []\n",
    "    used_idx = 0\n",
    "\n",
    "    n1_per_set = int(round(n0 * target_ratio / (1 - target_ratio)))\n",
    "    if n1_per_set == 0:\n",
    "        return []\n",
    "\n",
    "    # ë‚´ë¶€ ìœ í‹¸: ì¹´í…Œê³ ë¦¬ dtypeì— ë§ëŠ” í† í° ì¤€ë¹„ + í•„ìš” ì‹œ ì¹´í…Œê³ ë¦¬ ì¶”ê°€\n",
    "    def _ensure_token_and_dtype(s: pd.Series, base_token):\n",
    "        if pd.api.types.is_categorical_dtype(s):\n",
    "            cat_dtype = s.cat.categories.dtype\n",
    "            # ë¬¸ìì—´/ê°ì²´ ì¹´í…Œê³ ë¦¬ë©´ ë¬¸ìì—´ í† í° ì‚¬ìš©\n",
    "            token = str(base_token) if getattr(cat_dtype, \"kind\", None) in (\"O\", \"U\", \"S\") else base_token\n",
    "            if token not in s.cat.categories:\n",
    "                s = s.cat.add_categories([token])\n",
    "            return s, token\n",
    "        # ë¹„ì¹´í…Œê³ ë¦¬ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        return s, base_token\n",
    "\n",
    "    # ë£¨í”„ ë°–ì—ì„œ RNG ì¤€ë¹„(ì„¸íŠ¸ë§ˆë‹¤ ë…ë¦½ì ì´ë‚˜ ì¬í˜„ì„± ìœ ì§€)\n",
    "    rng_lf = np.random.RandomState(seed_pair[0])\n",
    "    rng_inv = np.random.RandomState(seed_pair[1])\n",
    "\n",
    "    while used_idx + n1_per_set <= n1:\n",
    "        sub_X0 = X_val0.copy()\n",
    "        sub_X1 = X_val1.iloc[used_idx:used_idx + n1_per_set]\n",
    "        sub_X = pd.concat([sub_X0, sub_X1], axis=0).reset_index(drop=True)\n",
    "        sub_y = pd.concat([\n",
    "            pd.Series([0] * len(sub_X0), dtype=int),\n",
    "            pd.Series([1] * len(sub_X1), dtype=int)\n",
    "        ], axis=0).reset_index(drop=True)\n",
    "\n",
    "        # -------------------------\n",
    "        # â‘  l_feat_14 / l_feat_12 (ê°™ì€ ì¸ë±ìŠ¤) ë§ˆìŠ¤í‚¹\n",
    "        # -------------------------\n",
    "        if mask_lf14_frac > 0.0:\n",
    "            n_mask = int(len(sub_X) * mask_lf14_frac)\n",
    "            if n_mask > 0:\n",
    "                mask_idx = rng_lf.choice(sub_X.index, size=n_mask, replace=False)\n",
    "\n",
    "                for col in [LF14_COL, \"l_feat_12\"]:\n",
    "                    if col in sub_X.columns:\n",
    "                        sub_X[col], tok = _ensure_token_and_dtype(sub_X[col], mask_token)\n",
    "                        sub_X.loc[mask_idx, col] = tok\n",
    "\n",
    "        # -------------------------\n",
    "        # â‘¡ inventory_id (ë…ë¦½ ì¸ë±ìŠ¤/ë¹„ìœ¨/ì‹œë“œ) ë§ˆìŠ¤í‚¹\n",
    "        # -------------------------\n",
    "        if mask_inventory_frac > 0.0 and inv_col in sub_X.columns:\n",
    "            n_mask_inv = int(len(sub_X) * mask_inventory_frac)\n",
    "            if n_mask_inv > 0:\n",
    "                mask_idx_inv = rng_inv.choice(sub_X.index, size=n_mask_inv, replace=False)\n",
    "                sub_X[inv_col], tok_inv = _ensure_token_and_dtype(sub_X[inv_col], mask_token)\n",
    "                sub_X.loc[mask_idx_inv, inv_col] = tok_inv\n",
    "\n",
    "        valid_sets.append((sub_X, sub_y))\n",
    "        used_idx += n1_per_set\n",
    "\n",
    "    return valid_sets\n",
    "\n",
    "\n",
    "def make_real_ratio_valid_sets_old(X_val, y_val, target_ratio=0.019075,\n",
    "                                mask_lf14_frac=0.15, mask_token=-111111):\n",
    "    X_val0 = X_val[y_val == 0].reset_index(drop=True)\n",
    "    X_val1 = X_val[y_val == 1].reset_index(drop=True)\n",
    "    n0, n1 = len(X_val0), len(X_val1)\n",
    "\n",
    "    valid_sets = []\n",
    "    used_idx = 0\n",
    "\n",
    "    n1_per_set = int(round(n0 * target_ratio / (1 - target_ratio)))\n",
    "    if n1_per_set == 0:\n",
    "        return []\n",
    "\n",
    "    while used_idx + n1_per_set <= n1:\n",
    "        sub_X0 = X_val0.copy()  # 0ì€ ì „ë¶€\n",
    "        sub_X1 = X_val1.iloc[used_idx:used_idx + n1_per_set]\n",
    "        sub_X = pd.concat([sub_X0, sub_X1], axis=0).reset_index(drop=True)\n",
    "        sub_y = pd.concat([\n",
    "            pd.Series([0] * len(sub_X0)),\n",
    "            pd.Series([1] * len(sub_X1))\n",
    "        ], axis=0).reset_index(drop=True)\n",
    "\n",
    "        # âœ… ë§ˆìŠ¤í‚¹ ì¶”ê°€: l_feat_14 ì»¬ëŸ¼ì—ì„œ ì¼ë¶€ë¥¼ mask_tokenìœ¼ë¡œ ì¹˜í™˜\n",
    "        if mask_lf14_frac > 0.0 and LF14_COL in sub_X.columns:\n",
    "            np.random.seed(724)\n",
    "            n_mask = int(len(sub_X) * mask_lf14_frac)\n",
    "            mask_indices = np.random.choice(sub_X.index, size=n_mask, replace=False)\n",
    "\n",
    "            # âœ… category íƒ€ì…ì´ë©´ ìƒˆ ì¹´í…Œê³ ë¦¬ ë¨¼ì € ì¶”ê°€\n",
    "            if isinstance(sub_X[LF14_COL].dtype, pd.CategoricalDtype):\n",
    "                if mask_token not in sub_X[LF14_COL].cat.categories:\n",
    "                    sub_X[LF14_COL] = sub_X[LF14_COL].cat.add_categories([mask_token])\n",
    "\n",
    "            # âœ… category íƒ€ì…ì´ë©´ ìƒˆ ì¹´í…Œê³ ë¦¬ ë¨¼ì € ì¶”ê°€\n",
    "            if isinstance(sub_X['l_feat_12'].dtype, pd.CategoricalDtype):\n",
    "                if mask_token not in sub_X['l_feat_12'].cat.categories:\n",
    "                    sub_X['l_feat_12'] = sub_X['l_feat_12'].cat.add_categories([mask_token])\n",
    "\n",
    "            sub_X.loc[mask_indices, LF14_COL] = mask_token\n",
    "            sub_X.loc[mask_indices, 'l_feat_12'] = mask_token\n",
    "\n",
    "        valid_sets.append((sub_X, sub_y))\n",
    "        used_idx += n1_per_set\n",
    "\n",
    "    return valid_sets\n",
    "\n",
    "def stratified_sample_by_column(df, col, n_samples, random_state=None):\n",
    "    \"\"\"\n",
    "    dfì—ì„œ col ê¸°ì¤€ stratified samplingìœ¼ë¡œ n_samplesë§Œí¼ ìƒ˜í”Œë§\n",
    "    \"\"\"\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=n_samples, random_state=random_state)\n",
    "    strat_col = df[col].astype(str)  # ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ë¡œ ì²˜ë¦¬\n",
    "    idx = np.arange(len(df))\n",
    "    train_idx, _ = next(sss.split(idx.reshape(-1, 1), strat_col))\n",
    "    return df.iloc[train_idx]\n",
    "\n",
    "# === [NEW] ë¡œê·¸/ëª¨ë¸ ì €ì¥ ìœ í‹¸ ===\n",
    "LOG_DIR = \"logs_re\"\n",
    "MODEL_DIR = \"Weights\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "LOG_PATH = os.path.join(LOG_DIR, \"lgbm_params_log.txt\")\n",
    "\n",
    "def _log_lgbm_params(seed, model_idx, fold_num, params_dict, score, path=LOG_PATH):\n",
    "    \"\"\"\n",
    "    ì‹œë“œ/ëª¨ë¸/í´ë“œ ë‹¨ìœ„ë¡œ íŒŒë¼ë¯¸í„°ì™€ ì ìˆ˜ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ì— ëˆ„ì  ê¸°ë¡.\n",
    "    \"\"\"\n",
    "    line1 = f'Seed {seed} ëª¨ë¸ {model_idx} í´ë“œ {fold_num} íŒŒë¼ë¯¸í„°: {json.dumps(params_dict, ensure_ascii=False)}\\n'\n",
    "    line2 = f\"Score: {score}\\n\\n\"\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:  \n",
    "        f.write(line1)\n",
    "        f.write(line2)\n",
    "\n",
    "def _save_lgbm_model(model, seed, model_idx, fold_num, dirpath=MODEL_DIR):\n",
    "    fname = f\"lgbm_seed{seed}_model{model_idx}_fold{fold_num}.pkl\"\n",
    "    fpath = os.path.join(dirpath, fname)\n",
    "    with open(fpath, \"wb\") as f:\n",
    "        cloudpickle.dump(model, f) \n",
    "\n",
    "# --------------------------\n",
    "# Main Ensemble with 5Fold + Multi Validation  (ê³ ì • íŒŒë¼ë¯¸í„° ì ìš©)\n",
    "# --------------------------\n",
    "X_test = test.copy()\n",
    "pos_df = train[train[\"clicked\"] == 1].reset_index(drop=True)\n",
    "neg_df = train[train[\"clicked\"] == 0].reset_index(drop=True)\n",
    "\n",
    "n_pos = len(pos_df)\n",
    "n_neg = len(neg_df)\n",
    "n_iters = int(np.ceil(n_neg / n_pos)) - 1\n",
    "print(f\"ğŸ” ë°˜ë³µ íšŸìˆ˜: {n_iters} (1:1 ë¹„ìœ¨ ìœ ì§€, ì „ì²´ 0 ìƒ˜í”Œ ì†Œì§„)\")\n",
    "\n",
    "seed_list = [724]\n",
    "all_seed_preds = []\n",
    "feature_importances = {\"lgbm\": []}\n",
    "\n",
    "for seed in tqdm(seed_list, desc=\"ğŸŒ± ì‹œë“œ ì•™ìƒë¸”\"):\n",
    "    test_preds_lgbm = []\n",
    "\n",
    "    pos_df_seed = pos_df.copy()\n",
    "    neg_df_seed = neg_df.copy()\n",
    "\n",
    "    for i in tqdm(range(n_iters), desc=f\"  ğŸ§  ëª¨ë¸ ì•™ìƒë¸” ë°˜ë³µ (seed={seed})\", position=1, leave=False):\n",
    "        print(\"=================== Model\", i + 1, \"=================\")\n",
    "\n",
    "        if len(neg_df_seed) < n_pos:\n",
    "            break\n",
    "        sampled_neg = neg_df_seed.sample(n=n_pos, random_state=seed + i)\n",
    "        neg_df_seed = neg_df_seed.drop(sampled_neg.index).reset_index(drop=True)\n",
    "\n",
    "        sampled_df = pd.concat([pos_df_seed, sampled_neg], axis=0).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "        X_train = sampled_df.drop(columns=[\"clicked\"])\n",
    "        y_train = sampled_df[\"clicked\"]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        fold_idx = 0\n",
    "        fold_scores_iter = {\"lgbm\": []}\n",
    "\n",
    "        if (i + 1) not in LGBM_PARAMS_FOLD1:\n",
    "            raise KeyError(f\"LGBM_PARAMS_FOLD1ì— ëª¨ë¸ ì¸ë±ìŠ¤ {(i+1)}ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        fixed_params = dict(LGBM_PARAMS_FOLD1[i + 1])  \n",
    "\n",
    "        for tr_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "            print(\"=================== Fold\", fold_idx + 1, \"=================\")\n",
    "\n",
    "            lf14_w_fold = make_lf14_weights(X_tr, col=LF14_COL)\n",
    "            custom_obj_fold = make_weighted_logloss_objective(lf14_w_fold)\n",
    "\n",
    "            model_lgbm = LGBMClassifier(**fixed_params, objective=custom_obj_fold)\n",
    "            model_lgbm.fit(X_tr, y_tr, categorical_feature=cat_list)\n",
    "\n",
    "            pred_lgbm = lgbm_proba1_from_raw(model_lgbm, X_test)\n",
    "            test_preds_lgbm.append(pred_lgbm)\n",
    "\n",
    "            feature_importances[\"lgbm\"].append(\n",
    "                pd.Series(model_lgbm.feature_importances_, index=X_tr.columns)\n",
    "            )\n",
    "\n",
    "            fold_idx += 1\n",
    "\n",
    "            valid_sets = make_real_ratio_valid_sets(X_val, y_val)\n",
    "            if valid_sets:\n",
    "                preds_val_lgb = lgbm_proba1_from_raw(model_lgbm, X_val)\n",
    "                scores = [ap_wll_scorer(yv, lgbm_proba1_from_raw(model_lgbm, Xv))\n",
    "                          for Xv, yv in valid_sets]\n",
    "                print(f\"LGBM Fold {fold_idx} | Mean: {np.mean(scores):.4f} | \"\n",
    "                      f\"Max: {np.max(scores):.4f} | Min: {np.min(scores):.4f}\")\n",
    "                obj_value = aggregate_scores_relative_downside_std(scores, lam=ROBUST_LAMBDA_RELATIVE_DSTD)\n",
    "                \n",
    "                params_to_log = dict(fixed_params)\n",
    "                params_to_log.pop(\"objective\", None)\n",
    "                _log_lgbm_params(\n",
    "                    seed=seed,\n",
    "                    model_idx=i + 1,\n",
    "                    fold_num=fold_idx,\n",
    "                    params_dict=params_to_log,\n",
    "                    score=float(obj_value)\n",
    "                )\n",
    "                _save_lgbm_model(model_lgbm, seed=seed, model_idx=i+1, fold_num=fold_idx)\n",
    "\n",
    "    avg_lgbm = np.mean(test_preds_lgbm, axis=0)\n",
    "    all_seed_preds.append(avg_lgbm)\n",
    "\n",
    "final_pred = np.mean(all_seed_preds, axis=0)\n",
    "submit['clicked'] = final_pred \n",
    "\n",
    "submit.to_csv(\"Fin.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
